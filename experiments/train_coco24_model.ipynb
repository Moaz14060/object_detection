{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T01:18:01.082018Z","iopub.execute_input":"2025-11-01T01:18:01.082574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# scripts/explore_coco.py (Kaggle version)\nimport os, json, random\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport cv2\nfrom collections import Counter\nimport pandas as pd\n\n# ---- USER CONFIG ----\nBASE_DIR = \"/kaggle/input/coco-2017-dataset/coco2017\"\nDATA_DIR = BASE_DIR\nANN_DIR = os.path.join(DATA_DIR, \"annotations\")\nTRAIN_ANN = os.path.join(ANN_DIR, \"instances_train2017.json\")\nVAL_ANN = os.path.join(ANN_DIR, \"instances_val2017.json\")\nIMG_DIR_TRAIN = os.path.join(DATA_DIR, \"train2017\")\nIMG_DIR_VAL = os.path.join(DATA_DIR, \"val2017\")\nOUTPUT_DIR = \"/kaggle/working/exploration_outputs\"\n\nSAMPLE_COUNT = 8\n\n# âœ… Selected 24 classes for autonomous-driving dataset\nSELECTED_CLASSES = [\n    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"train\",\n    \"traffic light\", \"stop sign\", \"fire hydrant\", \"bench\", \"parking meter\",\n    \"umbrella\", \"backpack\", \"handbag\", \"tie\", \"cell phone\", \"dog\", \"cat\",\n    \"horse\", \"bird\", \"skateboard\", \"boat\", \"suitcase\"\n]\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --------------------------------------------------------\ndef explore(ann_file, img_dir, split_name=\"train\"):\n    print(f\"\\n=== Exploring {split_name.upper()} split ===\")\n    coco = COCO(ann_file)\n    cats = coco.loadCats(coco.getCatIds())\n    cat_id_to_name = {c['id']: c['name'] for c in cats}\n    selected_cat_ids = coco.getCatIds(catNms=SELECTED_CLASSES)\n\n    # --- Basic statistics ---\n    img_ids = coco.getImgIds()\n    images = coco.loadImgs(img_ids)\n    ann_ids = coco.getAnnIds()\n    anns = coco.loadAnns(ann_ids)\n\n    widths = [img['width'] for img in images]\n    heights = [img['height'] for img in images]\n    class_counts = Counter()\n    for a in anns:\n        if a['category_id'] in selected_cat_ids:\n            class_counts[cat_id_to_name[a['category_id']]] += 1\n\n    objs_per_image = [len(coco.getAnnIds(imgIds=img['id'], catIds=selected_cat_ids)) for img in images]\n\n    summary = {\n        \"split\": split_name,\n        \"num_images\": len(images),\n        \"num_annotations_total\": len(anns),\n        \"num_annotations_selected\": sum(class_counts.values()),\n        \"image_width_mean\": np.mean(widths),\n        \"image_height_mean\": np.mean(heights),\n        \"avg_objects_selected_per_image\": np.mean(objs_per_image)\n    }\n    pd.DataFrame([summary]).to_csv(os.path.join(OUTPUT_DIR, f\"summary_{split_name}.csv\"), index=False)\n    print(\"Summary:\", summary)\n\n    # --- Visualization section ---\n    sns.set_style(\"whitegrid\")\n\n    # 1. Class distribution\n    plt.figure(figsize=(10,6))\n    classes = list(class_counts.keys())\n    counts = [class_counts[c] for c in classes]\n    sns.barplot(x=counts, y=classes, palette=\"crest\")\n    plt.title(f\"Class Distribution - {split_name}\")\n    plt.xlabel(\"Object count\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, f\"class_distribution_{split_name}.png\"))\n    plt.close()\n\n    # 2. Objects per image histogram\n    plt.figure(figsize=(7,5))\n    plt.hist(objs_per_image, bins=30, color=\"royalblue\")\n    plt.xlabel(\"Objects per image\")\n    plt.ylabel(\"Number of images\")\n    plt.title(f\"Objects per Image Histogram ({split_name})\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, f\"objects_per_image_{split_name}.png\"))\n    plt.close()\n\n    # 3. Image dimension distribution\n    plt.figure(figsize=(6,6))\n    plt.scatter(widths, heights, s=10, alpha=0.4)\n    plt.xlabel(\"Width\")\n    plt.ylabel(\"Height\")\n    plt.title(f\"Image Resolution Scatter ({split_name})\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, f\"image_resolution_{split_name}.png\"))\n    plt.close()\n\n    # --- Sample image visualization ---\n    print(\"Generating example annotated images...\")\n    sample_img_ids = random.sample(img_ids, min(SAMPLE_COUNT, len(img_ids)))\n    for i, img_id in enumerate(sample_img_ids):\n        img_info = coco.loadImgs(img_id)[0]\n        img_path = os.path.join(img_dir, img_info['file_name'])\n        if not os.path.exists(img_path):\n            continue\n        img = cv2.imread(img_path)\n        anns_ids = coco.getAnnIds(imgIds=img_id, catIds=selected_cat_ids)\n        anns_sel = coco.loadAnns(anns_ids)\n        for ann in anns_sel:\n            x, y, w, h = map(int, ann['bbox'])\n            cat_name = cat_id_to_name[ann['category_id']]\n            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n            cv2.putText(img, cat_name, (x, max(15,y-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n        out_path = os.path.join(OUTPUT_DIR, f\"sample_{split_name}_{i}.jpg\")\n        cv2.imwrite(out_path, img)\n\n    # --- Automatic insights ---\n    print(\"\\nðŸ“Š Key Insights:\")\n    top5 = class_counts.most_common(5)\n    print(f\"Top 5 most common objects: {top5}\")\n    rare5 = class_counts.most_common()[-5:]\n    print(f\"Least common objects: {rare5}\")\n    print(f\"Average objects per image: {summary['avg_objects_selected_per_image']:.2f}\")\n    print(f\"Average image size: {summary['image_width_mean']:.0f}Ã—{summary['image_height_mean']:.0f}\")\n\n    print(\"\\nðŸ’¡ Analysis Q&A:\")\n    print(\"Q1: Which objects dominate the dataset?\")\n    print(f\"A1: {top5[0][0]} appears most frequently, suggesting focus on urban scenes.\")\n    print(\"Q2: Are there underrepresented classes?\")\n    print(f\"A2: The rarest are {', '.join([c for c,_ in rare5])}, consider augmenting them.\")\n    print(\"Q3: How dense are scenes?\")\n    print(f\"A3: On average {summary['avg_objects_selected_per_image']:.1f} relevant objects per image.\")\n    print(\"Q4: Are image sizes consistent?\")\n    print(f\"A4: Widths range {min(widths)}â€“{max(widths)}, heights {min(heights)}â€“{max(heights)}.\")\n    print(\"Q5: What do examples show?\")\n    print(\"A5: Sample images saved with bounding boxes illustrate diversity in object placement and scale.\\n\")\n\n    return summary, class_counts\n\n\nif __name__ == \"__main__\":\n    print(\"Starting Dataset Exploration ...\")\n    explore(TRAIN_ANN, IMG_DIR_TRAIN, \"train\")\n    explore(VAL_ANN, IMG_DIR_VAL, \"val\")\n    print(f\"\\nâœ… Exploration finished. Check visual reports in:\\n{OUTPUT_DIR}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# scripts/filter_and_convert_kaggle.py\nimport os, json, shutil\nfrom pycocotools.coco import COCO\nfrom tqdm import tqdm\nfrom PIL import Image\nimport numpy as np\nimport yaml\n\n# ==========================================================\n# âœ… USER CONFIG (Kaggle Version of Your Original Script)\n# ==========================================================\nBASE_DIR = \"/kaggle/working\"\nDATA_DIR = \"/kaggle/input/coco-2017-dataset/coco2017\"\nANN_DIR = os.path.join(DATA_DIR, \"annotations\")\n\nTRAIN_ANN = os.path.join(ANN_DIR, \"instances_train2017.json\")\nVAL_ANN = os.path.join(ANN_DIR, \"instances_val2017.json\")\n\nIMG_DIR_TRAIN = os.path.join(DATA_DIR, \"train2017\")\nIMG_DIR_VAL = os.path.join(DATA_DIR, \"val2017\")\n\nOUT = os.path.join(BASE_DIR, \"outputs\", \"filtered_dataset\")\nIMG_SIZE = 640  # final image size\n\n# âœ… Debug: Check paths\nprint(\"TRAIN_ANN exists:\", os.path.exists(TRAIN_ANN))\nprint(\"VAL_ANN exists:\", os.path.exists(VAL_ANN))\nprint(\"IMG_DIR_TRAIN exists:\", os.path.exists(IMG_DIR_TRAIN))\nprint(\"IMG_DIR_VAL exists:\", os.path.exists(IMG_DIR_VAL))\n\n# ==========================================================\n# COCO Classes of Interest\n# ==========================================================\nSELECTED_CLASSES = [\n    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"train\",\n    \"traffic light\", \"stop sign\", \"fire hydrant\", \"bench\", \"parking meter\",\n    \"umbrella\", \"backpack\", \"handbag\", \"tie\", \"cell phone\", \"dog\", \"cat\",\n    \"horse\", \"bird\", \"skateboard\", \"boat\", \"suitcase\"\n]\n\nSPLIT_MAP = {\n    \"train\": (TRAIN_ANN, IMG_DIR_TRAIN),\n    \"val\": (VAL_ANN, IMG_DIR_VAL)\n}\n\n# Create output folders\nos.makedirs(OUT, exist_ok=True)\nfor s in [\"train\", \"val\"]:\n    os.makedirs(os.path.join(OUT, s, \"images\"), exist_ok=True)\n    os.makedirs(os.path.join(OUT, s, \"labels\"), exist_ok=True)\n\n\n# ==========================================================\n# Helper Functions\n# ==========================================================\ndef build_cat_mapping(coco, selected_names):\n    selected_cat_ids = coco.getCatIds(catNms=selected_names)\n    print(\"Selected cat IDs:\", selected_cat_ids)\n    if not selected_cat_ids:\n        print(\"âš ï¸ Warning: No matching categories found! Check class names.\")\n    mapping = {cid: i for i, cid in enumerate(selected_cat_ids)}\n    return mapping, selected_cat_ids\n\n\ndef process_split(split):\n    ann_file, img_dir = SPLIT_MAP[split]\n    print(f\"\\n=== Processing {split} split ===\")\n    print(\"Annotation file:\", ann_file)\n    print(\"Exists?\", os.path.exists(ann_file))\n    coco = COCO(ann_file)\n\n    mapping, selected_cat_ids = build_cat_mapping(coco, SELECTED_CLASSES)\n    selected_cat_names = [coco.loadCats([cid])[0]['name'] for cid in selected_cat_ids]\n\n    test_car_id = coco.getCatIds(catNms=[\"car\"])\n    test_car_imgs = coco.getImgIds(catIds=test_car_id)\n    print(\"Debug - Car ID:\", test_car_id, \"| Images found:\", len(test_car_imgs))\n\n    img_ids = list(set().union(*[coco.getImgIds(catIds=[cid]) for cid in selected_cat_ids]))\n    print(f\"{split}: {len(img_ids)} images with selected classes\")\n\n    for img_id in tqdm(img_ids):\n        img_meta = coco.loadImgs(img_id)[0]\n        fname = img_meta['file_name']\n        src_path = os.path.join(img_dir, fname)\n        if not os.path.exists(src_path):\n            continue\n\n        im = Image.open(src_path).convert('RGB')\n        orig_w, orig_h = im.size\n        im_resized = im.resize((IMG_SIZE, IMG_SIZE))\n        out_img_path = os.path.join(OUT, split, \"images\", fname)\n        im_resized.save(out_img_path, quality=95)\n\n        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=selected_cat_ids, iscrowd=None)\n        anns = coco.loadAnns(ann_ids)\n\n        yolo_lines = []\n        for ann in anns:\n            coco_cat_id = ann['category_id']\n            if coco_cat_id not in mapping:\n                continue\n            new_class = mapping[coco_cat_id]\n            x, y, w, h = ann['bbox']\n            x_c = (x + w / 2.0) / orig_w\n            y_c = (y + h / 2.0) / orig_h\n            w /= orig_w\n            h /= orig_h\n            yolo_lines.append(f\"{new_class} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\")\n\n        label_path = os.path.join(OUT, split, \"labels\", os.path.splitext(fname)[0] + \".txt\")\n        with open(label_path, \"w\") as f:\n            if len(yolo_lines) > 0:\n                f.write(\"\\n\".join(yolo_lines))\n\n    inv_map = {v: k for k, v in mapping.items()}\n    names = [coco.loadCats([inv_map[i]])[0]['name'] for i in range(len(inv_map))]\n    return names\n\n\n# ==========================================================\n# Main Execution\n# ==========================================================\nif __name__ == \"__main__\":\n    names = None\n    for s in [\"val\"]:  # change to [\"train\", \"val\"] to process both\n        names = process_split(s)\n\n    data_yaml = {\n        'train': os.path.abspath(os.path.join(OUT, \"train\", \"images\")),\n        'val': os.path.abspath(os.path.join(OUT, \"val\", \"images\")),\n        'test': os.path.abspath(os.path.join(OUT, \"val\", \"images\")),\n        'nc': len(names),\n        'names': names\n    }\n\n    yaml_path = os.path.join(BASE_DIR, \"data.yaml\")\n    with open(yaml_path, \"w\") as f:\n        yaml.dump(data_yaml, f)\n\n    print(\"\\nâœ… Conversion complete!\")\n    print(\"data.yaml created at:\", yaml_path)\n    print(\"Classes:\", names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics==8.2.77\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/outputs/filtered_dataset/train/images | head\n!ls /kaggle/working/outputs/filtered_dataset/val/images | head\n!cat /kaggle/working/data.yaml\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"yolov8l.pt\")  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train(\n    data=\"/kaggle/working/data.yaml\",\n    epochs=120,\n    imgsz=800,\n    batch=8,\n    workers=2,                 # keep low for Kaggle stability\n    optimizer=\"AdamW\",\n    lr0=0.0005,\n    cos_lr=True,\n    augment=True,\n    dropout=0.2,\n    patience=10,               # early stop if no improvement\n    device=0,                  # use GPU 0\n    project=\"yolo8_coco24_runs\",\n    name=\"yolo8_coco24_highacc\",\n    cache=True,\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Step 1: Disable W&B (prevents hangs) ===\nimport os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n\n# === Step 2: Install/upgrade ultralytics ===\n!pip install -U ultralytics > /dev/null\n\n# === Step 3: Verify GPU ===\n!nvidia-smi\n\n# === Step 4: Train YOLOv8 ===\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"yolov8l.pt\")  # or \"yolov8x.pt\" for extra accuracy (slower)\n\nmodel.train(\n    data=\"/kaggle/working/data.yaml\",\n    epochs=120,\n    imgsz=800,\n    batch=8,\n    workers=2,                 # keep low for Kaggle stability\n    optimizer=\"AdamW\",\n    lr0=0.0005,\n    cos_lr=True,\n    augment=True,\n    dropout=0.2,\n    patience=10,               # early stop if no improvement\n    device=0,                  # use GPU 0\n    project=\"yolo8_coco24_runs\",\n    name=\"yolo8_coco24_highacc\",\n    cache=True,\n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}